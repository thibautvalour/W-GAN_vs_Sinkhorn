{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will investigate the ability of Wasserstein-GAN (W-GAN) to approximate the 1-Wasserstein distance. We will begin by formulating the problem and selecting ground truth distributions for which the true optimal transport (OT) distances are known.\n",
    "\n",
    "# Problem Formulation\n",
    "\n",
    "**Objective:** Given two probability distributions P and Q, we want to compute the 1-Wasserstein distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ground Truth Distributions : \n",
    "We will select a set of ground truth distributions for which the true optimal transport (OT) distances are known. In this case, we will consider 1D and 2D Gaussians.\n",
    "\n",
    "First, let's define a function to generate ground truth Gaussian distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussians(num_distributions, dim):\n",
    "    means = [torch.randn(dim) for _ in range(num_distributions)]\n",
    "    covariances = [torch.randn(dim, dim) for _ in range(num_distributions)]\n",
    "    covariances = [A @ A.T for A in covariances]  # Ensure positive semi-definite\n",
    "    \n",
    "    return means, covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a set of ground truth Gaussian distributions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distributions = 10\n",
    "dim = 2\n",
    "\n",
    "means, covariances = generate_gaussians(num_distributions, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to compute the true OT distances between these Gaussian distributions. For simplicity, we will compute the distances only between consecutive pairs of distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_ot_distance(mean1, cov1, mean2, cov2):\n",
    "    mean_diff = mean2 - mean1\n",
    "    cov_sum = cov1 + cov2\n",
    "    ot_distance = (torch.sqrt(torch.dot(mean_diff.t(), mean_diff)) \n",
    "                   + torch.trace(cov_sum - 2 * torch.sqrt(torch.sqrt(cov1) @ (torch.sqrt(cov2) @ torch.sqrt(cov1)))))\n",
    "    return ot_distance\n",
    "\n",
    "true_ot_distances = [true_ot_distance(means[i], covariances[i], means[i+1], covariances[i+1]) for i in range(num_distributions - 1)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. W-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 2 of the plan, we will implement the W-GAN model and train the critic on the selected ground truth distributions. Then, we will evaluate the performance of the W-GAN by comparing its approximated Wasserstein distances with the known true OT distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the critic neural network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the critic\n",
    "input_dim = dim\n",
    "critic = Critic(input_dim).to(device)\n",
    "\n",
    "# Set up training parameters\n",
    "epochs = 1000\n",
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(critic.parameters(), lr=lr)\n",
    "clip_value = 0.01\n",
    "n_critic_updates = 5\n",
    "\n",
    "# Define a function to sample from Gaussian distributions\n",
    "def sample_from_gaussian(mean, cov, n_samples):\n",
    "    L = torch.linalg.cholesky(cov)\n",
    "    samples = torch.randn(n_samples, cov.shape[0])\n",
    "    return samples @ L + mean\n",
    "\n",
    "# W-GAN training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(num_distributions - 1):\n",
    "        for _ in range(n_critic_updates):\n",
    "            # Sample data from both distributions\n",
    "            real_data = sample_from_gaussian(means[i], covariances[i], batch_size).to(device)\n",
    "            fake_data = sample_from_gaussian(means[i+1], covariances[i+1], batch_size).to(device)\n",
    "            \n",
    "            # Calculate the Wasserstein distance approximation\n",
    "            real_scores = critic(real_data)\n",
    "            fake_scores = critic(fake_data)\n",
    "            wasserstein_approx = real_scores.mean() - fake_scores.mean()\n",
    "            \n",
    "            # Update the critic\n",
    "            critic_loss = -wasserstein_approx\n",
    "            optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clip the critic's weights\n",
    "            for param in critic.parameters():\n",
    "                param.data.clamp_(-clip_value, clip_value)\n",
    "                \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}, Critic Loss: {critic_loss.item()}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the W-GAN is trained, we can evaluate its performance by comparing the approximated Wasserstein distances with the known true OT distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgan_approximated_distance(mean1, cov1, mean2, cov2, n_samples=1000):\n",
    "    real_data = sample_from_gaussian(mean1, cov1, n_samples).to(device)\n",
    "    fake_data = sample_from_gaussian(mean2, cov2, n_samples).to(device)\n",
    "    \n",
    "    real_scores = critic(real_data)\n",
    "    fake_scores = critic(fake_data)\n",
    "    \n",
    "    return real_scores.mean() - fake_scores.mean()\n",
    "\n",
    "wgan_distances = [wgan_approximated_distance(means[i], covariances[i], means[i+1], covariances[i+1]) for i in range(num_distributions - 1)]\n",
    "\n",
    "# Compare W-GAN approximated distances with true OT distances\n",
    "for i in range(num_distributions - 1):\n",
    "    print(f'Pair {i + 1}: True OT Distance = {true_ot_distances[i].item()}, W-GAN Approximated Distance = {wgan_distances[i].item()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sinkhorn divergence\n",
    "\n",
    "First, let's define a function to compute the Sinkhorn divergence between two distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_divergence(mu, nu, C, epsilon, n_iter=100):\n",
    "    K = torch.exp(-C / epsilon)\n",
    "    u = torch.ones_like(mu)\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        v = nu / (K.T @ u)\n",
    "        u = mu / (K @ v)\n",
    "        \n",
    "    P = torch.diag(u) @ K @ torch.diag(v)\n",
    "    return torch.sum(P * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost matrix between two sets of samples\n",
    "def compute_cost_matrix(X, Y):\n",
    "    X_sq = torch.sum(X ** 2, dim=1, keepdim=True)\n",
    "    Y_sq = torch.sum(Y ** 2, dim=1, keepdim=True).T\n",
    "    XY = X @ Y.T\n",
    "    return X_sq - 2 * XY + Y_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "n_samples = 1000\n",
    "\n",
    "sinkhorn_distances = []\n",
    "\n",
    "for i in range(num_distributions - 1):\n",
    "    X = sample_from_gaussian(means[i], covariances[i], n_samples).to(device)\n",
    "    Y = sample_from_gaussian(means[i+1], covariances[i+1], n_samples).to(device)\n",
    "    \n",
    "    mu = torch.ones(X.shape[0], device=device) / X.shape[0]\n",
    "    nu = torch.ones(Y.shape[0], device=device) / Y.shape[0]\n",
    "    \n",
    "    C = compute_cost_matrix(X, Y)\n",
    "    \n",
    "    sinkhorn_dist = sinkhorn_divergence(mu, nu, C, epsilon)\n",
    "    sinkhorn_distances.append(sinkhorn_dist.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distributions - 1):\n",
    "    print(f'Pair {i + 1}: True OT Distance = {true_ot_distances[i].item()}, W-GAN Approximated Distance = {wgan_distances[i].item()}, Sinkhorn Distance = {sinkhorn_distances[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
